name: backup

on:
  workflow_dispatch:
  schedule:
    # * is a special character in YAML so you have to quote this string
    - cron:  '0 20 * * *'

jobs:
  backup:
    runs-on: ubuntu-latest
    env: 
      EXPORT_FILENAME: 'export.zip'

    steps:

      - name: Checkout
        uses: actions/checkout@v2

      - uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Git Config
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

      - name: Python script
        run: |
          cat <<EOF > notion_export_gen.py
          #!/usr/bin/env python
          import os
          import json
          import time
          import urllib
          import urllib.request

          TZ = os.getenv("TZ", "Europe/Amsterdam")
          NOTION_API = os.getenv('NOTION_API', 'https://www.notion.so/api/v3')
          EXPORT_FILENAME = os.getenv('EXPORT_FILENAME', 'export.zip')
          NOTION_TOKEN_V2 = os.environ['NOTION_TOKEN_V2']
          NOTION_SPACE_ID = os.environ['NOTION_SPACE_ID']

          ENQUEUE_TASK_PARAM = {
              "task": {
                  "eventName": "exportSpace", "request": {
                      "spaceId": NOTION_SPACE_ID,
                      "exportOptions": {"exportType": "markdown", "timeZone": TZ, "locale": "en"}
                  }
              }
          }


          def request(endpoint: str, params: object):
              req = urllib.request.Request(
                  f'{NOTION_API}/{endpoint}',
                  data=json.dumps(params).encode('utf8'),
                  headers={
                      'content-type': 'application/json',
                      'cookie': f'token_v2={NOTION_TOKEN_V2}; '
                  },
              )
              response = urllib.request.urlopen(req)
              return json.loads(response.read().decode('utf8'))


          def export():
              task_id = request('enqueueTask', ENQUEUE_TASK_PARAM).get('taskId')
              print(f'Enqueued task {task_id}')

              while True:
                  time.sleep(2)
                  tasks = request("getTasks", {"taskIds": [task_id]}).get('results')
                  task = next(t for t in tasks if t.get('id') == task_id)
                  print(f'\rPages exported: {task.get("status").get("pagesExported")}', end="")

                  if task.get('state') == 'success':
                      break

              export_url = task.get('status').get('exportURL')
              print(f'\nExport created, downloading: {export_url}')

              urllib.request.urlretrieve(
                  export_url, EXPORT_FILENAME,
                  reporthook=lambda c, bs, ts: print(f"\r{int(c * bs * 100 / ts)}%", end="")
              )
              print(f'\nDownload complete: {EXPORT_FILENAME}')


          if __name__ == "__main__":
              export()
          
          EOF

      - name: Bash script
        run: |
          cat <<EOF > merge_gen.sh
          #!/bin/bash
          set -e

          mkdir -p backup
          rm -rf backup/* && unzip -q "$EXPORT_FILENAME" -d backup/

          stats="\$(git diff --shortstat | xargs)"
          if [ -z "\${stats}" ]; then stats=none; fi

          printf "Updated: %s\n\nUpdates: %s" "\$(date)" "\$stats" > UPDATE.md

          git add backup UPDATE.md && git commit -m "Update: \$(date)" -m "\$stats"
          git push origin HEAD:master
          EOF

      - name: ðŸ’¾ Backup
        run: |
          chmod +x notion_export_gen.py && chmod +x merge_gen.sh
          ./notion_export_gen.py && ./merge_gen.sh

        env:
          NOTION_TOKEN_V2: ${{ secrets.NOTION_TOKEN_V2 }}
          NOTION_SPACE_ID: ${{ secrets.NOTION_SPACE_ID }}

